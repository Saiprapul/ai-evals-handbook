<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Getting Started with AI Evaluation | AI Evals Handbook</title>
    <meta name="description"
        content="Start evaluating your AI systems in 30 minutes. A practical quick-start guide for implementing AI evaluation in production.">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="css/framework-page.css">
    <link rel="stylesheet" href="css/docs.css">
</head>

<body>
    <header class="docs-header">
        <div class="container">
            <a href="./" class="docs-logo"><span class="logo-icon">E</span>AI Evals Handbook</a>
            <div class="header-actions">
                <a href="https://github.com/saiprapul/ai-evals-handbook" target="_blank" class="btn btn-sm">GitHub</a>
            </div>
        </div>
    </header>

    <div class="docs-layout">
        <aside class="docs-sidebar">
            <div class="sidebar-group">
                <div class="sidebar-title">Foundations</div>
                <a href="getting-started.html" class="sidebar-link active">Getting Started</a>
                <a href="ecosystem.html" class="sidebar-link">The Ecosystem</a>
                <a href="glossary.html" class="sidebar-link">Glossary</a>
                <a href="faq.html" class="sidebar-link">FAQ</a>
            </div>
            <div class="sidebar-group">
                <div class="sidebar-title">Architectures</div>
                <a href="frameworks/rag-evaluation.html" class="sidebar-link">RAG Systems</a>
                <a href="frameworks/human-in-the-loop.html" class="sidebar-link">Agentic AI</a>
                <a href="frameworks/governance.html" class="sidebar-link">Enterprise Governance</a>
                <a href="frameworks/drift-monitoring.html" class="sidebar-link">Drift Monitoring</a>
            </div>
            <div class="sidebar-group">
                <div class="sidebar-title">Techniques</div>
                <a href="frameworks/consequence-weighted.html" class="sidebar-link">Consequence Scoring</a>
                <a href="frameworks/llm-as-judge.html" class="sidebar-link">LLM-as-Judge</a>
            </div>
            <div class="sidebar-group">
                <div class="sidebar-title">Case Studies</div>
                <a href="case-studies/query-drift-rag.html" class="sidebar-link">Query Drift</a>
                <a href="case-studies/hallucination-reduction.html" class="sidebar-link">Hallucination Reduction</a>
                <a href="case-studies/embedding-drift.html" class="sidebar-link">Embedding Drift</a>
            </div>
            <div class="sidebar-group">
                <div class="sidebar-title">Implementation</div>
                <a href="code/eval_pipeline.html" class="sidebar-link">EvalPipeline</a>
                <a href="code/consequence_scorer.html" class="sidebar-link">Scorers</a>
                <a href="code/rag_evaluator.html" class="sidebar-link">RAG Evaluator</a>
                <a href="code/confidence_calibrator.html" class="sidebar-link">Calibrator</a>
                <a href="best-practices.html" class="sidebar-link">Best Practices</a>
            </div>
        </aside>

        <main class="docs-main">
            <div class="docs-content">
                <div class="breadcrumbs">
                    <a href="./">Home</a><span class="separator">/</span><span>Foundations</span><span
                        class="separator">/</span><span>Getting Started</span>
                </div>

                <h1>Getting Started</h1>
                <p class="framework-subtitle">From "Vibes" to Production-Grade Evaluation in 4 Steps.</p>
                <hr style="margin: 2rem 0; border: none; border-bottom: 1px solid var(--border);">

                <div class="content-grid" style="grid-template-columns: 1fr;">
                    <section id="step1">
                        <h2>Step 1: The Golden Dataset</h2>
                        <p>Most teams fail because they start coding metrics first. Don't. Start with the data.</p>
                        <p>A <strong>Golden Dataset</strong> is a curated list of inputs and expected outputs that
                            define "success".</p>
                        <ul class="checklist">
                            <li><strong>Coverage:</strong> Include happy paths, edge cases, and adversarial attacks.
                            </li>
                            <li><strong>Source:</strong> Use real production logs if possible (anonymized).</li>
                            <li><strong>Format:</strong> Keep it simple (JSON/CSV).</li>
                        </ul>
                        <div class="code-block">
                            <div class="code-header"><span>dataset_sample.json</span></div>
                            <pre><code>[
  {
    <span class="string">"input"</span>: <span class="string">"I want to return my order #12345"</span>,
    <span class="string">"context"</span>: [<span class="string">"Return Policy: Returns allowed within 30 days..."</span>],
    <span class="string">"expected_output"</span>: <span class="string">"I can help with that. Is the item in its original condition?"</span>,
    <span class="string">"tags"</span>: [<span class="string">"support"</span>, <span class="string">"returns"</span>]
  }
]</code></pre>
                        </div>
                    </section>

                    <section id="step2">
                        <h2>Step 2: Selecting Metrics</h2>
                        <p>Avoid "kitchen sink" metrics. Choose 2-3 that actually map to business value.</p>
                        <div class="comparison-table">
                            <table>
                                <thead>
                                    <tr>
                                        <th>Metric</th>
                                        <th>What it measures</th>
                                        <th>When to use</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><strong>Faithfulness</strong></td>
                                        <td>Does the answer come <em>only</em> from the context?</td>
                                        <td>RAG systems (prevent hallucinations).</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Semantic Similarity</strong></td>
                                        <td>Is the meaning close to the Golden Answer? (Embedding distance)</td>
                                        <td>Q&A where accurate phrasing matters.</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Tool Call Safety</strong></td>
                                        <td>Did the agent call `delete_db` with correct params?</td>
                                        <td>Agentic/Action-based systems.</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </section>

                    <section id="step3">
                        <h2>Step 3: The Evaluation Loop</h2>
                        <p>Run your evals as part of your CI/CD pipeline, not just locally on your laptop.</p>
                        <div class="code-block">
                            <div class="code-header"><span>pipeline_runner.py</span></div>
                            <pre><code><span class="keyword">for</span> example <span class="keyword">in</span> golden_dataset:
    <span class="comment"># 1. Generate</span>
    actual_output = model.generate(example[<span class="string">"input"</span>])
    
    <span class="comment"># 2. Evaluate (Parallelize this in production)</span>
    faith_score = measure_faithfulness(actual_output, example[<span class="string">"context"</span>])
    sim_score = measure_similarity(actual_output, example[<span class="string">"expected_output"</span>])
    
    <span class="comment"># 3. Log</span>
    logger.log({
        <span class="string">"input"</span>: example[<span class="string">"input"</span>],
        <span class="string">"scores"</span>: { <span class="string">"faithfulness"</span>: faith_score, <span class="string">"similarity"</span>: sim_score }
    })</code></pre>
                        </div>
                    </section>
                </div>
                <div class="docs-footer-nav">
                    <div></div>
                    <a href="ecosystem.html" class="nav-card">
                        <span class="label">Next</span>
                        <span class="title">The Ecosystem â†’</span>
                    </a>
                </div>
            </div>
        </main>
    </div>
    <script src="js/main.js"></script>
</body>

</html>