<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Where AI Systems Fail | AI Evals Handbook</title>
    <meta name="description"
        content="Understand where AI systems fail as they evolve from RAG to Agents and Multimodal, and why evaluation must evolve with them.">
    <link rel="canonical" href="https://saiprapul.github.io/ai-evals-handbook/ecosystem.html">
    <meta property="og:title" content="Where AI Systems Fail | AI Evals Handbook">
    <meta property="og:description" content="Understand where AI systems fail as they evolve from RAG to Agents and Multimodal.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://saiprapul.github.io/ai-evals-handbook/ecosystem.html">
    <meta property="og:site_name" content="AI Evals Handbook">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Where AI Systems Fail | AI Evals Handbook">
    <meta name="twitter:description" content="Understand where AI systems fail as they evolve from RAG to Agents and Multimodal.">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="css/framework-page.css">
    <link rel="stylesheet" href="css/docs.css">
</head>

<body>
    <!-- Persistent Header -->
    <header class="docs-header">
        <div class="container">
            <a href="./" class="docs-logo"><span class="logo-icon">E</span>AI Evals Handbook</a>
            <div class="header-actions">
                <a href="why-evals-matter.html" class="btn btn-sm btn-primary">Start Here</a>
                <a href="https://github.com/saiprapul/ai-evals-handbook" target="_blank" class="btn btn-sm">GitHub</a>
            </div>
        </div>
    </header>

    <div class="docs-layout">
        <!-- Persistent Sidebar -->
        <aside class="docs-sidebar" id="sidebar"></aside>

        <!-- Main Content -->
        <main class="docs-main">
            <div class="docs-content">
                <!-- Breadcrumbs -->
                <div class="breadcrumbs">
                    <a href="./">Home</a><span class="separator">/</span><span>Scoping</span><span
                        class="separator">/</span><span>Where Failure Emerges</span>
                </div>

                <h1>Where AI Systems Fail</h1>
                <p class="framework-subtitle">As AI systems evolve from simple prompts to autonomous agents, the ways they fail evolve too. Understanding failure modes is the first step to evaluating them.</p>

                <hr style="margin: 2rem 0; border: none; border-bottom: 1px solid var(--border);">

                <div class="content-grid" style="grid-template-columns: 1fr;">


                    <section>


                        <h2 id="quick-answer">Quick Answer</h2>


                        <p>Most AI failures come from the system, not just the model. This page maps the AI stack to failure modes so teams can evaluate the right layer and fix the real cause.</p>


                    </section>


                    <section>


                        <h2 id="tldr">TL;DR</h2>


                        <ul>


                            <li>Failures can originate in data, retrieval, prompting, or product logic.</li>


                            <li>Map the system end-to-end before choosing metrics.</li>


                            <li>Evaluate the layer that can actually be changed.</li>


                        </ul>


                    </section>


                    <section>


                        <h2 id="faq">FAQ</h2>


                        <h3>Where do AI failures usually happen?</h3>


                        <p>Most regressions come from upstream data changes, retrieval errors, or policy shifts, not from the base model alone.</p>


                        <h3>How do I scope an eval?</h3>


                        <p>Start with the system boundary, identify failure points, then choose metrics and data for the highest-risk nodes.</p>


                        <h3>What should I measure first?</h3>


                        <p>Measure retrieval quality and policy adherence first in RAG systems, then answer quality and user impact.</p>


                    </section>

                    <section id="evolution">
                        <h2>1. The Rapid Evolution of AI Systems</h2>
                        <p>We are witnessing a shift from static models to dynamic, complex systems. As the complexity
                            of the system increases, the difficulty of evaluation compounds.</p>

                        <div class="diagram-card">
                            <svg class="diagram-svg" viewBox="0 0 900 200" role="img"
                                aria-label="Evolution from prompting to RAG to agents to multimodal systems">
                                <defs>
                                    <marker id="eco-arrow" viewBox="0 0 10 10" refX="8" refY="5" markerWidth="6"
                                        markerHeight="6" orient="auto-start-reverse">
                                        <path d="M 0 0 L 10 5 L 0 10 z" class="diagram-arrow"></path>
                                    </marker>
                                </defs>

                                <rect class="diagram-node diagram-node-accent" x="60" y="70" width="160" height="60"
                                    rx="12"></rect>
                                <text x="140" y="103" text-anchor="middle" class="diagram-label">Prompting</text>

                                <rect class="diagram-node diagram-node-accent" x="260" y="70" width="160" height="60"
                                    rx="12"></rect>
                                <text x="340" y="103" text-anchor="middle" class="diagram-label">RAG</text>

                                <rect class="diagram-node diagram-node-accent" x="460" y="70" width="160" height="60"
                                    rx="12"></rect>
                                <text x="540" y="103" text-anchor="middle" class="diagram-label">Agents</text>

                                <rect class="diagram-node diagram-node-accent" x="660" y="70" width="170" height="60"
                                    rx="12"></rect>
                                <text x="745" y="103" text-anchor="middle" class="diagram-label">Multimodal</text>

                                <path class="diagram-line-solid" d="M 220 100 L 260 100"
                                    marker-end="url(#eco-arrow)"></path>
                                <path class="diagram-line-solid" d="M 420 100 L 460 100"
                                    marker-end="url(#eco-arrow)"></path>
                                <path class="diagram-line-solid" d="M 620 100 L 660 100"
                                    marker-end="url(#eco-arrow)"></path>

                                <text x="240" y="60" class="diagram-note">Add data</text>
                                <text x="440" y="60" class="diagram-note">Add tools</text>
                                <text x="640" y="60" class="diagram-note">Add modalities</text>
                            </svg>
                        </div>

                        <div class="system-type-grid">
                            <div class="system-type-card">
                                <div class="system-icon">üîç</div>
                                <h3>RAG (Retrieval-Augmented Generation)</h3>
                                <p>Systems that look up external private data before answering. The challenge is
                                    evaluating both the <em>retrieval</em> (did I find the right doc?) and
                                    <em>generation</em> (did I summarize it correctly?).
                                </p>
                                <a href="https://docs.llamaindex.ai/en/stable/" target="_blank" class="learn-more">Learn
                                    about RAG (LlamaIndex) ‚Üó</a>
                            </div>

                            <div class="system-type-card">
                                <div class="system-icon">ü§ñ</div>
                                <h3>Agentic AI</h3>
                                <p>Systems that use tools (API calls, web search) to solve multi-step problems.
                                    Evaluation here is about <em>reasoning paths</em> and <em>safety</em>‚Äîdid the agent
                                    call the delete API by mistake?</p>
                                <a href="https://langchain.com/agents" target="_blank" class="learn-more">Learn about
                                    Agents (LangChain) ‚Üó</a>
                            </div>

                            <div class="system-type-card">
                                <div class="system-icon">üñºÔ∏è</div>
                                <h3>Multimodal</h3>
                                <p>Systems that see, hear, and speak. Evals move beyond text matching to semantic
                                    understanding of images and audio alignment.</p>
                                <a href="https://openai.com/research/gpt-4" target="_blank" class="learn-more">Learn
                                    about Multimodal (OpenAI) ‚Üó</a>
                            </div>
                        </div>
                    </section>

                    <section id="state-of-evals">
                        <h2>2. The State of Evals: Why "Vibes" Fail</h2>
                        <p>In traditional software, we have unit tests: <code>assert 2 + 2 == 4</code>. In probabilistic
                            AI, we have <strong>"Vibes-Based Evaluation"</strong>‚Äîlooking at an output and saying,
                            "Yeah, looks good."</p>

                        <p>This fails in production because:</p>
                        <ul>
                            <li><strong>Drift:</strong> A model update might fix one bug but break 10 others
                                (Regressions).</li>
                            <li><strong>Scale:</strong> You can't manually review 10,000 logs a day.</li>
                            <li><strong>Subjectivity:</strong> "Good" means different things to Legal vs. Marketing.
                            </li>
                        </ul>

                        <div class="diagram-card">
                            <svg class="diagram-svg" viewBox="0 0 900 260" role="img"
                                aria-label="Evaluation layer connects outputs to deterministic, model-graded, and human feedback">
                                <defs>
                                    <marker id="eval-arrow" viewBox="0 0 10 10" refX="8" refY="5" markerWidth="6"
                                        markerHeight="6" orient="auto-start-reverse">
                                        <path d="M 0 0 L 10 5 L 0 10 z" class="diagram-arrow"></path>
                                    </marker>
                                </defs>

                                <rect class="diagram-node" x="40" y="100" width="160" height="60" rx="12"></rect>
                                <text x="120" y="132" text-anchor="middle" class="diagram-label">Input Query</text>

                                <rect class="diagram-node" x="240" y="100" width="160" height="60" rx="12"></rect>
                                <text x="320" y="132" text-anchor="middle" class="diagram-label">AI System</text>

                                <rect class="diagram-node" x="440" y="100" width="160" height="60" rx="12"></rect>
                                <text x="520" y="132" text-anchor="middle" class="diagram-label">Actual Output</text>

                                <rect class="diagram-node diagram-node-accent" x="640" y="90" width="200" height="80"
                                    rx="12"></rect>
                                <text x="740" y="120" text-anchor="middle" class="diagram-label">Evaluation Layer</text>
                                <text x="740" y="140" text-anchor="middle" class="diagram-note">Deterministic + Human</text>

                                <rect class="diagram-node" x="640" y="20" width="200" height="50" rx="10"></rect>
                                <text x="740" y="50" text-anchor="middle" class="diagram-note">Code Assertions</text>

                                <rect class="diagram-node" x="640" y="190" width="200" height="50" rx="10"></rect>
                                <text x="740" y="220" text-anchor="middle" class="diagram-note">Model-Graded Evals</text>

                                <rect class="diagram-node" x="440" y="190" width="160" height="50" rx="10"></rect>
                                <text x="520" y="220" text-anchor="middle" class="diagram-note">Human Feedback</text>

                                <rect class="diagram-node" x="240" y="190" width="160" height="50" rx="10"></rect>
                                <text x="320" y="220" text-anchor="middle" class="diagram-note">Score Report</text>

                                <path class="diagram-line-solid" d="M 200 130 L 240 130"
                                    marker-end="url(#eval-arrow)"></path>
                                <path class="diagram-line-solid" d="M 400 130 L 440 130"
                                    marker-end="url(#eval-arrow)"></path>
                                <path class="diagram-line-solid" d="M 600 130 L 640 130"
                                    marker-end="url(#eval-arrow)"></path>

                                <path class="diagram-line-solid" d="M 740 90 L 740 70"
                                    marker-end="url(#eval-arrow)"></path>
                                <path class="diagram-line-solid" d="M 740 170 L 740 190"
                                    marker-end="url(#eval-arrow)"></path>

                                <path class="diagram-line-solid" d="M 520 190 L 520 160"
                                    marker-end="url(#eval-arrow)"></path>
                                <path class="diagram-line-solid" d="M 440 215 L 400 215"
                                    marker-end="url(#eval-arrow)"></path>
                                <path class="diagram-line" d="M 240 215 L 240 160 L 320 160"
                                    marker-end="url(#eval-arrow)"></path>
                            </svg>
                        </div>

                        <div class="callout">
                            <h4>The Industry Shift</h4>
                            <p>Leading companies are moving to <strong>Custom Evaluation Frameworks</strong>. Instead of
                                using generic benchmarks (like MMLU), they build "Golden Datasets" from their own
                                production logs and evaluate against business-specific rules.</p>
                        </div>
                    </section>

                    <section id="landscape">
                        <h2>3. The Tooling Landscape</h2>
                        <p>You don't need to build everything from scratch. The open-source ecosystem provides powerful
                            primitives.</p>

                        <div class="ecosystem-grid">
                            <div class="ecosystem-card">
                                <div class="card-header">
                                    <h3>DeepEval</h3>
                                    <span class="badge open-source">Open Source</span>
                                </div>
                                <p>Pytest for LLMs. Best for developers who want to run evals as part of their CI/CD
                                    pipeline.</p>
                            </div>

                            <div class="ecosystem-card">
                                <div class="card-header">
                                    <h3>Ragas</h3>
                                    <span class="badge open-source">Open Source</span>
                                </div>
                                <p>Specialized metrics for RAG pipelines (Context Precision, Faithfulness).</p>
                            </div>

                            <div class="ecosystem-card">
                                <div class="card-header">
                                    <h3>Arize / Phoenix</h3>
                                    <span class="badge open-source">Open Source Core</span>
                                </div>
                                <p>Observability first. Great for tracing complex agent workflows and visualizing
                                    traces.</p>
                            </div>
                        </div>
                    </section>

                </div>

                <!-- Footer Navigation -->
                <div class="docs-footer-nav">
                    <a href="what-are-evals.html" class="nav-card">
                        <span class="label">Previous</span>
                        <span class="title">&larr; What Evals Are</span>
                    </a>
                    <a href="frameworks/governance.html" class="nav-card">
                        <span class="label">Next</span>
                        <span class="title">Risk-First Scoping &rarr;</span>
                    </a>
                </div>

            </div>
        </main>
    </div>

    <script src="js/main.js"></script>
    <script src="js/sidebar.js"></script>
</body>

</html>
