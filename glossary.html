<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Evaluation Glossary | AI Evals Handbook</title>
    <meta name="description" content="Common terms in AI evaluation and safety. Definitions for drift, hallucination, faithfulness, LLM-as-Judge, and more.">
    <link rel="canonical" href="https://saiprapul.github.io/ai-evals-handbook/glossary.html">
    <meta property="og:title" content="AI Evaluation Glossary | AI Evals Handbook">
    <meta property="og:description" content="Common terms in AI evaluation and safety. Drift, hallucination, faithfulness, LLM-as-Judge.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://saiprapul.github.io/ai-evals-handbook/glossary.html">
    <meta property="og:site_name" content="AI Evals Handbook">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="AI Evaluation Glossary | AI Evals Handbook">
    <meta name="twitter:description" content="Common terms in AI evaluation and safety.">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="css/framework-page.css">
    <link rel="stylesheet" href="css/docs.css">
</head>

<body>
    <header class="docs-header">
        <div class="container">
            <a href="./" class="docs-logo"><span class="logo-icon">E</span>AI Evals Handbook</a>
            <div class="header-actions">
                <a href="why-evals-matter.html" class="btn btn-sm btn-primary">Start Here</a>
                <a href="https://github.com/saiprapul/ai-evals-handbook" target="_blank" class="btn btn-sm">GitHub</a>
            </div>
        </div>
    </header>
    <div class="docs-layout">
        <aside class="docs-sidebar" id="sidebar"></aside>
        <main class="docs-main">
            <div class="docs-content">
                <div class="breadcrumbs">
                    <a href="./">Home</a>
                    <span class="separator">/</span>
                    <span>Reference</span>
                    <span class="separator">/</span>
                    <span>Glossary</span>
                </div>
                <h1>Glossary of Terms</h1>
                <p class="framework-subtitle">Common terms in AI evaluation and safety.</p>
                <hr style="margin: 2rem 0; border: none; border-bottom: 1px solid var(--border);">

                <div class="content">


                    <section>


                        <h2 id="quick-answer">Quick Answer</h2>


                        <p>This glossary defines core evaluation terms so teams can align on metrics, failure modes, and workflows.</p>


                    </section>


                    <section>


                        <h2 id="tldr">TL;DR</h2>


                        <ul>


                            <li>Use these definitions to standardize eval discussions.</li>


                            <li>Map each term to a measurable metric or rubric.</li>


                            <li>Keep the glossary updated as your system evolves.</li>


                        </ul>


                    </section>


                    <section>


                        <h2 id="faq">FAQ</h2>


                        <h3>Faithfulness vs. accuracy - what is the difference?</h3>


                        <p>Accuracy measures correctness against a reference answer; faithfulness measures whether the answer is supported by evidence.</p>


                        <h3>What is the RAG triad?</h3>


                        <p>The RAG triad is Query, Context, and Response - each must be evaluated separately to diagnose failures.</p>


                        <h3>What is drift?</h3>


                        <p>Drift is a shift in data distribution or embedding space that degrades performance over time.</p>


                    </section>
                    <section class="glossary-grid">
                        <div class="glossary-item">
                            <h3>Drift</h3>
                            <p>The degradation of model performance over time due to changes in input data distribution
                                (Data Drift) or user expectations (Concept Drift).</p>
                        </div>
                        <div class="glossary-item">
                            <h3>Hallucination</h3>
                            <p>When an LLM generates a confident but factually incorrect answer that is not grounded in
                                the provided context.</p>
                        </div>
                        <div class="glossary-item">
                            <h3>Faithfulness</h3>
                            <p>A metric measuring whether the generated answer is derived <em>only</em> from the
                                retrieved context, without adding external information.</p>
                        </div>
                        <div class="glossary-item">
                            <h3>LLM-as-Judge</h3>
                            <p>The practice of using a stronger model (e.g., GPT-4) to evaluate the outputs of a weaker
                                model or application.</p>
                        </div>
                    </section>
                </div>
                <div class="docs-footer-nav">
                    <a href="code/confidence_calibrator.html" class="nav-card">
                        <span class="label">Previous</span>
                        <span class="title">&larr; Calibrator</span>
                    </a>
                    <a href="faq.html" class="nav-card">
                        <span class="label">Next</span>
                        <span class="title">FAQ &rarr;</span>
                    </a>
                </div>
            </div>
        </main>
    </div>
    <script src="js/main.js"></script>
    <script src="js/sidebar.js"></script>
</body>

</html>
